{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aGMZP9UPqYgZ"
      },
      "source": [
        "# Detecting Spam email\n",
        "\n",
        "## Group Members and Roles\n",
        "\n",
        "1. Zafir Jamal â€“ Project Coordinator\n",
        "2. Joseph Maswi - Programmer\n",
        "3. Anthony Kwasi - Researcher\n",
        "4. Kevin Mungai â€“ Program Leader\n",
        "5. Alex Samia â€“ Program Coordinator\n",
        "\n",
        "## Project Overview\n",
        "\n",
        "We seek to develop an AI program that will be able to detect email spam and notify the user. The program will help the users in determining the mail is safe and protect their machines/devices from viruses and unnecessary messages.\n",
        "\n",
        "## Purpose of the project\n",
        "\n",
        "Anti-spam software works to identify and prevent potential harmful email from reaching users inboxes. Spam is defined as an uninvited and undesired message (spam); frequently, spam advertises a product, which may be valid (though still unwanted) or malevolent. Anti-spam protocols define what constitutes spam.\n",
        "\n",
        "## Goals for the project ðŸ¥…\n",
        "\n",
        "In order to protect legitimate users from being impacted, spam detection aims to create effective and efficient methods for automatically identifying spams and their sources.\n",
        "To find emails that may contain malware.\n",
        "\n",
        "## Proposed key feature ðŸ”‘\n",
        "\n",
        "Classify emails as spam(1) or not spam (ham)(0) using machine learning techniques.\n",
        "\n",
        "## Inspiration ðŸ’¡\n",
        "\n",
        "Inspired by [inspiration](https://blog.logrocket.com/email-spam-detector-python-machine-learning/)\n",
        "\n",
        "Uploading sample data from local computer to **Google Colab** environment.\n",
        "This data is obtained from [spam.csv](https://raw.githubusercontent.com/SmallLion/Python-Projects/main/Spam-detection/spam.csv)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Declaring our imports."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 71,
      "metadata": {
        "id": "kRm89rXpgo9Z"
      },
      "outputs": [],
      "source": [
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "import string\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn import svm\n",
        "from pathlib import Path\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Loading our data set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "id": "MdX6vLkJlL5X"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>v1</th>\n",
              "      <th>v2</th>\n",
              "      <th>Unnamed: 2</th>\n",
              "      <th>Unnamed: 3</th>\n",
              "      <th>Unnamed: 4</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>ham</td>\n",
              "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>ham</td>\n",
              "      <td>Ok lar... Joking wif u oni...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>spam</td>\n",
              "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>ham</td>\n",
              "      <td>U dun say so early hor... U c already then say...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>ham</td>\n",
              "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "     v1                                                 v2 Unnamed: 2  \\\n",
              "0   ham  Go until jurong point, crazy.. Available only ...        NaN   \n",
              "1   ham                      Ok lar... Joking wif u oni...        NaN   \n",
              "2  spam  Free entry in 2 a wkly comp to win FA Cup fina...        NaN   \n",
              "3   ham  U dun say so early hor... U c already then say...        NaN   \n",
              "4   ham  Nah I don't think he goes to usf, he lives aro...        NaN   \n",
              "\n",
              "  Unnamed: 3 Unnamed: 4  \n",
              "0        NaN        NaN  \n",
              "1        NaN        NaN  \n",
              "2        NaN        NaN  \n",
              "3        NaN        NaN  \n",
              "4        NaN        NaN  "
            ]
          },
          "execution_count": 39,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Read the CVS file\n",
        "# To run locally.\n",
        "\n",
        "df = pd.read_csv(\"spam.csv\")\n",
        "\n",
        "# Print the first 5 rows of data\n",
        "df.head(5)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WXHXyHF9mbAs",
        "outputId": "a82280d4-c61f-486a-bce2-0bb664f77248"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(5572, 5)"
            ]
          },
          "execution_count": 40,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Print the shape of document(Get the number of rows and columns)\n",
        "df.shape\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LNdQh4lbmlwo",
        "outputId": "8d3f878d-e0aa-4e4c-98e7-5fbbc98fe767"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Index(['v1', 'v2', 'Unnamed: 2', 'Unnamed: 3', 'Unnamed: 4'], dtype='object')"
            ]
          },
          "execution_count": 41,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Get the columns names\n",
        "df.columns\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Cleaning our data set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3JRktYdamx11",
        "outputId": "2dab6efe-07c9-4d76-9dc6-db232aa39d81"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(5169, 5)"
            ]
          },
          "execution_count": 42,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Check for duplicates and remove them\n",
        "df.drop_duplicates(inplace=True)\n",
        "\n",
        "# show new shape\n",
        "df.shape\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j0w1W2a-oB59",
        "outputId": "86a67f09-f104-4db2-dcba-5f7601a80b5a"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "v1               0\n",
              "v2               0\n",
              "Unnamed: 2    5126\n",
              "Unnamed: 3    5159\n",
              "Unnamed: 4    5164\n",
              "dtype: int64"
            ]
          },
          "execution_count": 43,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# show missing data(NAN, NaN, na) for each column\n",
        "df.isnull().sum()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Creating some utilities for cleaning our data set."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 72,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oB-doI-wqFUq",
        "outputId": "3ea72e6b-8982-479a-a8ae-0a842c6e2a11"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to\n",
            "[nltk_data]     /home/kevinmungai/usiu/spam_email_detector...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 72,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Download the stopwords package to the parent directory.\n",
        "nltk.download(\"stopwords\", download_dir=Path.cwd().parent)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "ZCEjbqrxqiwv"
      },
      "outputs": [],
      "source": [
        "def process_text(text: str) -> list[str]:\n",
        "    \"\"\"\n",
        "    Process the text by:\n",
        "    1. Remove punctuation\n",
        "    2. Remove stopwords\n",
        "    3. Return list of clean text words\n",
        "    \"\"\"\n",
        "\n",
        "    # 1.\n",
        "    nopunc = [char for char in text if char not in string.punctuation]\n",
        "    nopunc = \"\".join(nopunc)\n",
        "\n",
        "    # 2\n",
        "    clean_words = [\n",
        "        word\n",
        "        for word in nopunc.split()\n",
        "        if word.lower() not in stopwords.words(\"english\")\n",
        "    ]\n",
        "\n",
        "    # 3\n",
        "    return clean_words\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>v1</th>\n",
              "      <th>v2</th>\n",
              "      <th>Unnamed: 2</th>\n",
              "      <th>Unnamed: 3</th>\n",
              "      <th>Unnamed: 4</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>ham</td>\n",
              "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>ham</td>\n",
              "      <td>Ok lar... Joking wif u oni...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>spam</td>\n",
              "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>ham</td>\n",
              "      <td>U dun say so early hor... U c already then say...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>ham</td>\n",
              "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "     v1                                                 v2 Unnamed: 2  \\\n",
              "0   ham  Go until jurong point, crazy.. Available only ...        NaN   \n",
              "1   ham                      Ok lar... Joking wif u oni...        NaN   \n",
              "2  spam  Free entry in 2 a wkly comp to win FA Cup fina...        NaN   \n",
              "3   ham  U dun say so early hor... U c already then say...        NaN   \n",
              "4   ham  Nah I don't think he goes to usf, he lives aro...        NaN   \n",
              "\n",
              "  Unnamed: 3 Unnamed: 4  \n",
              "0        NaN        NaN  \n",
              "1        NaN        NaN  \n",
              "2        NaN        NaN  \n",
              "3        NaN        NaN  \n",
              "4        NaN        NaN  "
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df.head()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HYAGajY_rmXX",
        "outputId": "0a58ce29-3d65-4465-aeaa-30806aa3296a"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0    [Go, jurong, point, crazy, Available, bugis, n...\n",
              "1                       [Ok, lar, Joking, wif, u, oni]\n",
              "2    [Free, entry, 2, wkly, comp, win, FA, Cup, fin...\n",
              "3        [U, dun, say, early, hor, U, c, already, say]\n",
              "4    [Nah, dont, think, goes, usf, lives, around, t...\n",
              "Name: v2, dtype: object"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# show the tokenization( a list of tokens also called lemmas)\n",
        "df[\"v2\"].head().apply(process_text)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Example on how to convert a matrix into token counts\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gdGohvi_tGg1",
        "outputId": "b2e4b45a-73ca-4226-c500-fc1ea84eb034"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Hello angelique angelique angelique\n",
            "test one two two three test test test\n",
            "  (0, 0)\t1\n",
            "  (0, 1)\t3\n",
            "  (1, 3)\t4\n",
            "  (1, 2)\t1\n",
            "  (1, 5)\t2\n",
            "  (1, 4)\t1\n",
            "\n",
            "(2, 6)\n"
          ]
        }
      ],
      "source": [
        "# Example\n",
        "message5 = \"Hello angelique angelique angelique\"\n",
        "message6 = \"test one two two three test test test\"\n",
        "\n",
        "# Convert the text to a matrix of token counts\n",
        "# bow => bag of words.\n",
        "bow5 = CountVectorizer(analyzer=process_text).fit_transform(\n",
        "    [[message5], [message6]]\n",
        ")\n",
        "print(message5)\n",
        "print(message6)\n",
        "print(bow5)\n",
        "\n",
        "print()\n",
        "\n",
        "print(bow5.shape)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Splitting our data set into 80% for training and 20% for testing."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "id": "o5evMulPo1d8"
      },
      "outputs": [],
      "source": [
        "# Split the selected data into 80% training and 20% testing\n",
        "\n",
        "label = df[\"v1\"]  # label (spam or ham).\n",
        "email = df[\"v2\"]  # email text.\n",
        "\n",
        "email_train, email_test, label_train, label_test = train_test_split(\n",
        "    email, label, test_size=0.2\n",
        ")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Training our model."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Using CountVectorizer to transform email text to matrix tokens."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {
        "id": "WYqAuVM3oG8x"
      },
      "outputs": [],
      "source": [
        "# Convert a collection of text to a matrix of tokens\n",
        "# Using a count vectorizer.\n",
        "cv = CountVectorizer(analyzer=process_text)\n",
        "email_features = cv.fit_transform(email_train)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Using Support Vector Machine model for training."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "metadata": {},
      "outputs": [],
      "source": [
        "# We'll be using a Support Vector Machine to classify our emails as ham or spam\n",
        "# The data used to train the model will come form the 80% of email and label.\n",
        "# But we'll have to convert the email to a matrix of tokens so that the support vector\n",
        "# can use it.\n",
        "svm_model = svm.SVC()\n",
        "svm_model = svm_model.fit(email_features, label_train)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Testing our model."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Using CountVectorizer to transform test email to matrix of tokens."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Transforming the email_test to a matrix of tokens\n",
        "email_feature_test = cv.transform(email_test)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Scoring our model by applying it to our test data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.9690522243713733"
            ]
          },
          "execution_count": 63,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Testing the accuracy of our model with the 20% test data\n",
        "# of email_test and label test.\n",
        "svm_model.score(email_feature_test, label_test)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Generating a classification report."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 69,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "         ham       0.97      1.00      0.98       907\n",
            "        spam       0.99      0.76      0.86       127\n",
            "\n",
            "    accuracy                           0.97      1034\n",
            "   macro avg       0.98      0.88      0.92      1034\n",
            "weighted avg       0.97      0.97      0.97      1034\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Generating the Classification Report\n",
        "feature_prediction = svm_model.predict(email_feature_test)\n",
        "print(\n",
        "    classification_report(\n",
        "        label_test,\n",
        "        feature_prediction,\n",
        "    )\n",
        ")\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3.10.4 ('.venv': poetry)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.7"
    },
    "vscode": {
      "interpreter": {
        "hash": "f48bd94a679e44c619b60adaa3b5b6691488a1ce36fb850a34114d3e3389919d"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
